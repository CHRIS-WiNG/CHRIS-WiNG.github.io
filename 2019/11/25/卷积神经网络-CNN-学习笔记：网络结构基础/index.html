<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="Coder">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      卷积神经网络(CNN)学习笔记：网络结构基础 | Zebin&#39;s Thoughts
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


<meta name="generator" content="Hexo 4.2.0"></head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>Zebin's Thoughts</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>卷积神经网络(CNN)学习笔记：网络结构基础</h2>
  <p class="post-date">2019-11-25</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><strong>卷积神经网络 (Convolutional Neural Network, CNN)</strong> 是DeepLearning中极具代表的网络结构之一，在图像处理领域取得了很大的成功，在国际标准的 ImageNet 数据集上，许多成功的模型都是基于 CNN 的。CNN 相较于传统的图像处理算法的优点之一在于，避免了对图像复杂的前期预处理过程（提取人工特征等），可以直接输入原始图像。</p>
<p>图像处理中，往往会将图像看成是一个或多个的二维向量，如之前博文中提到的 MNIST 手写体图片就可以看做是一个 28 × 28 的二维向量（黑白图片，只有一个颜色通道；如果是 RGB 表示的彩色图片则有三个颜色通道，可表示为三张二维向量）。传统的神经网络都是采用全连接的方式，即输入层到隐藏层的神经元都是全部连接的，这样做将导致参数量巨大，使得网络训练耗时甚至难以训练，而 CNN 则通过<strong><code>局部连接</code></strong>、<strong><code>权值共享</code></strong>等方法避免这一困难，有趣的是，这些方法都是受到现代生物神经网络相关研究的启发（感兴趣可阅读以下部分）。</p>
<img src="https://s2.ax1x.com/2019/11/25/MvUJ2T.md.png" alt="MvUJ2T.md.png" style="zoom:150%;" />


<p>下面重点介绍下 CNN 中的<strong>局部连接 (Sparse Connectivity)</strong> 和<strong>权值共享 (Shared Weights)</strong> 方法，理解它们很重要。</p>
<h3 id="局部连接与权值共享"><a href="#局部连接与权值共享" class="headerlink" title="局部连接与权值共享"></a>局部连接与权值共享</h3><p>下图是一个很经典的图示，左边是全连接，右边是局部连接。</p>
<img src="https://s2.ax1x.com/2019/11/25/MvUUr4.jpg" alt="MvUUr4.jpg" style="zoom:150%;" />


<p>对于一个 1000 × 1000 的输入图像而言，如果下一个隐藏层的神经元数目为 10^6 个，采用全连接则有 1000 × 1000 × 10^6 = 10^12 个权值参数，如此数目巨大的参数几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中 10 × 10 的局部图像相连接，那么此时的权值参数数量为 10 × 10 × 10^6 = 10^8，将直接减少 4 个数量级。</p>
<p>尽管减少了几个数量级，但参数数量依然较多。能不能再进一步减少呢？能！方法就是<strong>权值共享</strong>。具体做法是，在局部连接中隐藏层的每一个神经元连接的是一个 10 × 10 的局部图像，因此有 10 × 10 个权值参数，<strong>将这 10 × 10 个权值参数共享给剩下的神经元，也就是说隐藏层中 10^6 个神经元的权值参数相同</strong>，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 <strong>10 × 10 个权值参数</strong>（也就是卷积核 (也称滤波器) 的大小），如下图。</p>
<img src="https://s2.ax1x.com/2019/11/25/MvaNfP.jpg" alt="MvaNfP.jpg" style="zoom:150%;" />


<p>这大概就是 CNN 的一个神奇之处，尽管只有这么少的参数，依旧有出色的性能。但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像的不同映射下的特征，称之为<strong><code>Feature Map</code></strong>。如果有 100 个卷积核，最终的权值参数也仅为 100 × 100 = 10^4 个而已。另外，偏置参数也是共享的，同一种滤波器共享一个。</p>
<p>卷积神经网络的核心思想是：局部感受野 (local field)，权值共享(shared filter)以及降采样(pooling)这三种思想结合起来，获得了某种程度的位移、尺度、形变不变性。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>下图是一个经典的 CNN 结构 —— <strong><code>LeNet-5</code></strong>。</p>
<p><img src="https://s2.ax1x.com/2019/11/25/Mvadl8.png" alt="Mvadl8.png"></p>
<p>可以看出，CNN 中主要有两种类型的网络层，分别是<strong>卷积层</strong>和<strong>池化 / 采样层 (Pooling)</strong>。卷积层的作用是提取图像的各种特征；池化层的作用是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度。  </p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层是卷积核在上一级输入层上通过逐一滑动窗口计算而得，<strong>卷积核中的每一个参数都相当于传统神经网络中的权值参数</strong>，与对应的局部像素相连接，将卷积核的各个参数与对应的局部像素值相乘之和，（通常还要再加上一个偏置参数），得到卷积层上的结果。如下图所示。</p>
<p><img src="https://s2.ax1x.com/2019/11/25/MvaDmQ.png" alt="MvaDmQ.png"></p>
<p>下面的动图能够更好地解释卷积过程：</p>
<img src="https://s2.ax1x.com/2019/11/25/Mvarwj.gif" alt="Mvarwj.gif" style="zoom:200%;" />


<h3 id="池化-采样层"><a href="#池化-采样层" class="headerlink" title="池化 / 采样层"></a>池化 / 采样层</h3><p>通过卷积层获得了图像的特征之后，理论上我们可以直接使用这些特征训练分类器（如 softmax），但是这样做将面临巨大的计算量的挑战，而且容易产生过拟合的现象。为了进一步降低网络训练参数及模型的过拟合程度，我们对卷积层进行<strong>池化 / 采样 (Pooling)</strong> 处理。池化 / 采样的方式通常有以下两种：</p>
<ul>
<li><strong>Max-Pooling</strong>: 选择 Pooling 窗口中的最大值作为采样值；</li>
<li><strong>Mean-Pooling</strong>: 将 Pooling 窗口中的所有值相加取平均，以平均值作为采样值；</li>
</ul>
<p>如下图所示。</p>
<p><img src="https://s2.ax1x.com/2019/11/25/Mvagf0.png" alt="Mvagf0.png"></p>
<h3 id="LeNet-5-网络详解"><a href="#LeNet-5-网络详解" class="headerlink" title="LeNet-5 网络详解"></a>LeNet-5 网络详解</h3><p>以上较详细地介绍了 CNN 的网络结构和基本原理，下面是<strong><code>LeNet-5</code></strong>的结构详解。</p>
<p><img src="https://s2.ax1x.com/2019/11/25/MvaWlT.png" alt="MvaWlT.png"></p>
<p><img src="https://s2.ax1x.com/2019/11/25/MvahXF.png" alt="MvahXF.png"></p>
<p><img src="https://s2.ax1x.com/2019/11/25/MvdaNR.png" alt="MvdaNR.png"></p>
<p><img src="https://s2.ax1x.com/2019/11/25/Mvd5gf.png" alt="Mvd5gf.png"></p>
<p><img src="https://s2.ax1x.com/2019/11/25/MvdjCq.png" alt="MvdjCq.png"></p>
<blockquote>
<p>C5是具有120个大小为5X5的卷积核的卷积层。每个单元连接到S4的所有16个特征图上的5X5邻域。这里，因为S4的特征图大小也是5X5，所以C5的输出大小是1X1。因此S4和C5之间是完全连接的。但仍将其标为卷积层，原因是如果LeNet-5输入变得更大而其结构保持不变，则其输出大小会大于1X1，即不是完全连接的层了。</p>
</blockquote>
<p><img src="https://s2.ax1x.com/2019/11/25/Mvdx2V.png" alt="Mvdx2V.png"></p>
<p><a href="https://zhuanlan.zhihu.com/p/58188998" target="_blank" rel="noopener">为什么LeNet5倒数第二个全连接层维度为84？ - 知乎</a></p>
<p><img src="https://s2.ax1x.com/2019/11/25/MvwpKU.png" alt="MvwpKU.png"></p>
<p>一个数字识别效果如下图所示：  </p>
<img src="https://s2.ax1x.com/2019/11/26/MzT4DU.png" alt="MzT4DU.png" style="zoom:200%;" />

</section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#DeepLearning" >
    <span class="tag-code">DeepLearning</span>
  </a>

  <a href="/tags#CNN" >
    <span class="tag-code">CNN</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2019/11/23/%E5%8A%A8%E6%80%81%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/">
        <span class="nav-arrow">← </span>
        
          动态二维数组的初始化
        
      </a>
    
    
      <a class="nav-right" href="/2019/12/25/Java-Stream%E6%80%BB%E7%BB%93/">
        
          Java Stream总结
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
    <!-- 二维码 END -->
    
      <!-- No Comment -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#概述"><span class="toc-nav-text">概述</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#局部连接与权值共享"><span class="toc-nav-text">局部连接与权值共享</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#网络结构"><span class="toc-nav-text">网络结构</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#卷积层"><span class="toc-nav-text">卷积层</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#池化-采样层"><span class="toc-nav-text">池化 &#x2F; 采样层</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#LeNet-5-网络详解"><span class="toc-nav-text">LeNet-5 网络详解</span></a></li></ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'https://zebin.wang/2019/11/25/卷积神经网络-CNN-学习笔记：网络结构基础/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>







    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2020 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->


<script src="/js/script.js"></script>

  </body>
</html>